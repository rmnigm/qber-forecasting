{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VirVmSsFJ2-w",
        "N2BRIM4vOEec"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "VirVmSsFJ2-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1hZkLnfJtYH",
        "outputId": "88712051-ec80-48eb-f2f3-b032e182a4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qber-forecasting'...\n",
            "remote: Enumerating objects: 456, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (211/211), done.\u001b[K\n",
            "remote: Total 456 (delta 141), reused 177 (delta 58), pack-reused 176\u001b[K\n",
            "Receiving objects: 100% (456/456), 47.13 MiB | 15.12 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n",
            "Updating files: 100% (29/29), done.\n",
            "Cloning into 'Autoformer'...\n",
            "remote: Enumerating objects: 371, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 371 (delta 157), reused 151 (delta 144), pack-reused 167\u001b[K\n",
            "Receiving objects: 100% (371/371), 2.20 MiB | 5.94 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rmnigm/qber-forecasting.git\n",
        "!git clone https://github.com/thuml/Autoformer.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import seaborn as sns\n",
        "import scipy.stats as sps\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "SfE018XWJ2SS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int) -> None:\n",
        "    \"\"\"Fix all the random seeds we can for reproducibility\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "GwLsEt_zNd1R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "dUIgCtm6NQ49"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "nqZs3PhkNQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qber_path = pathlib.Path('qber-forecasting')"
      ],
      "metadata": {
        "id": "uVBtKyNAKVF1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pl.read_csv(qber_path / 'datasets' / 'data.csv')\n",
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "27KIHhcAK4SB",
        "outputId": "a8dccd83-a2b8-4930-dfc5-77a0b270f91b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 8)\n",
              "┌────────────┬──────────────┬────────────────┬─────────┬─────────┬──────────┬──────────┬──────────┐\n",
              "│ id         ┆ e_mu_current ┆ e_mu_estimated ┆ e_nu_1  ┆ e_nu_2  ┆ q_mu     ┆ q_nu1    ┆ q_nu2    │\n",
              "│ ---        ┆ ---          ┆ ---            ┆ ---     ┆ ---     ┆ ---      ┆ ---      ┆ ---      │\n",
              "│ i64        ┆ f64          ┆ f64            ┆ f64     ┆ f64     ┆ f64      ┆ f64      ┆ f64      │\n",
              "╞════════════╪══════════════╪════════════════╪═════════╪═════════╪══════════╪══════════╪══════════╡\n",
              "│ 1506053531 ┆ 0.01298      ┆ 0.01164        ┆ 0.01904 ┆ 0.17794 ┆ 0.550377 ┆ 0.164911 ┆ 0.008094 │\n",
              "│ 1506053531 ┆ 0.01283      ┆ 0.00961        ┆ 0.01672 ┆ 0.20868 ┆ 0.564295 ┆ 0.167629 ┆ 0.006639 │\n",
              "│ 1506053531 ┆ 0.01268      ┆ 0.0059         ┆ 0.01337 ┆ 0.20442 ┆ 0.564179 ┆ 0.16411  ┆ 0.007052 │\n",
              "│ 1506053531 ┆ 0.01129      ┆ 0.00988        ┆ 0.01637 ┆ 0.18453 ┆ 0.573555 ┆ 0.167174 ┆ 0.006663 │\n",
              "│ 1506053531 ┆ 0.01169      ┆ 0.01338        ┆ 0.01783 ┆ 0.11478 ┆ 0.569296 ┆ 0.169658 ┆ 0.006823 │\n",
              "└────────────┴──────────────┴────────────────┴─────────┴─────────┴──────────┴──────────┴──────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>e_mu_current</th><th>e_mu_estimated</th><th>e_nu_1</th><th>e_nu_2</th><th>q_mu</th><th>q_nu1</th><th>q_nu2</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1506053531</td><td>0.01298</td><td>0.01164</td><td>0.01904</td><td>0.17794</td><td>0.550377</td><td>0.164911</td><td>0.008094</td></tr><tr><td>1506053531</td><td>0.01283</td><td>0.00961</td><td>0.01672</td><td>0.20868</td><td>0.564295</td><td>0.167629</td><td>0.006639</td></tr><tr><td>1506053531</td><td>0.01268</td><td>0.0059</td><td>0.01337</td><td>0.20442</td><td>0.564179</td><td>0.16411</td><td>0.007052</td></tr><tr><td>1506053531</td><td>0.01129</td><td>0.00988</td><td>0.01637</td><td>0.18453</td><td>0.573555</td><td>0.167174</td><td>0.006663</td></tr><tr><td>1506053531</td><td>0.01169</td><td>0.01338</td><td>0.01783</td><td>0.11478</td><td>0.569296</td><td>0.169658</td><td>0.006823</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PolarsDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 data_path: str | pathlib.Path,\n",
        "                 window_size: int,\n",
        "                 data_format: str = 'csv',\n",
        "                 dtype: torch.dtype = torch.float32,\n",
        "                 columns: list[str] | None = None,\n",
        "                 device: torch.device = None,\n",
        "                 offset: int | float = None,\n",
        "                 limit: int | float = None\n",
        "                 ):\n",
        "        assert window_size is not None, data_path is not None\n",
        "        self.data_format = data_format\n",
        "        self.window_size = window_size\n",
        "        self.build_dataset(data_path, offset, limit, columns)\n",
        "        self.device = device or torch.device('cpu')\n",
        "        self.dtype = dtype\n",
        "\n",
        "    def build_dataset(self, data_path, offset, limit, columns) -> None:\n",
        "        assert self.data_format in ('csv', 'parquet')\n",
        "        if self.data_format == 'csv':\n",
        "          dataframe = pl.scan_csv(data_path)\n",
        "        elif self.data_format == 'parquet':\n",
        "          dataframe = pl.scan_parquet(data_path)\n",
        "        length = dataframe.select(pl.count()).collect().item()\n",
        "        offset, limit = self.calculate_offset_limit(offset, limit, length)\n",
        "        columns = columns or dataframe.columns\n",
        "        dataframe = (\n",
        "            dataframe\n",
        "            .select(columns)\n",
        "            .slice(offset, limit)\n",
        "        )\n",
        "        self.data_array = dataframe.collect().to_numpy()\n",
        "        self.dataset = np.lib.stride_tricks.sliding_window_view(\n",
        "            self.data_array,\n",
        "            self.window_size + 1,\n",
        "            axis=0\n",
        "            )\n",
        "        self.shape = self.dataset.shape[1:]\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_offset_limit(offset, limit, length) -> tuple[int, int]:\n",
        "        if offset is None:\n",
        "          offset = 0\n",
        "        else:\n",
        "          offset = offset if offset >= 1 else int(offset * length)\n",
        "        if limit is None:\n",
        "          limit = length\n",
        "        else:\n",
        "          limit = limit if limit >= 1 else int(limit * length)\n",
        "        return offset, limit\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f'PolarsDataset(len={self.__len__()})'\n",
        "\n",
        "    def __getitem__(self, idx) -> tuple[Tensor, Tensor]:\n",
        "        x = torch.tensor(self.dataset[idx][:, :-1].T, dtype=self.dtype).to(self.device)\n",
        "        y = torch.tensor(self.dataset[idx][:, -1], dtype=self.dtype).to(self.device)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "Sa4Fz9jWLA0w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\n",
        "    'e_mu_current',\n",
        "    'e_nu_1',\n",
        "    'e_nu_2',\n",
        "    'q_mu',\n",
        "    'q_nu1',\n",
        "    'q_nu2'\n",
        "]"
      ],
      "metadata": {
        "id": "8ctr4D6mnWUx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PolarsDataset(qber_path / 'datasets' / 'data.csv',\n",
        "                              window_size=30,\n",
        "                              columns=columns,\n",
        "                              device=device,\n",
        "                              limit=0.75)\n",
        "test_dataset = PolarsDataset(qber_path / 'datasets' / 'data.csv',\n",
        "                             window_size=30,\n",
        "                             columns=columns,\n",
        "                             device=device,\n",
        "                             offset=0.75)\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        "    )"
      ],
      "metadata": {
        "id": "iddX6R5JNCVg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoformer Ideas"
      ],
      "metadata": {
        "id": "N2BRIM4vOEec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "class AutoCorrelation(nn.Module):\n",
        "    \"\"\"\n",
        "    AutoCorrelation Mechanism with the following two phases:\n",
        "    (1) period-based dependencies discovery\n",
        "    (2) time delay aggregation\n",
        "    This block can replace the self-attention family mechanism seamlessly.\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(AutoCorrelation, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def time_delay_agg_training(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the training phase.\n",
        "        \"\"\"\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
        "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_inference(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the inference phase.\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_full(self, values, corr):\n",
        "        \"\"\"\n",
        "        Standard version of Autocorrelation\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
        "        return delays_agg\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        if L > S:\n",
        "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
        "            values = torch.cat([values, zeros], dim=1)\n",
        "            keys = torch.cat([keys, zeros], dim=1)\n",
        "        else:\n",
        "            values = values[:, :L, :, :]\n",
        "            keys = keys[:, :L, :, :]\n",
        "\n",
        "        # period-based dependencies\n",
        "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        res = q_fft * torch.conj(k_fft)\n",
        "        corr = torch.fft.irfft(res, n=L, dim=-1)\n",
        "\n",
        "        # time delay agg\n",
        "        if self.training:\n",
        "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "        else:\n",
        "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class AutoCorrelationLayer(nn.Module):\n",
        "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AutoCorrelationLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "\n",
        "        self.inner_correlation = correlation\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "\n",
        "        out, attn = self.inner_correlation(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), attn"
      ],
      "metadata": {
        "id": "QNsPfvgTOGAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class my_Layernorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Special designed layernorm for the seasonal part\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super(my_Layernorm, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_hat = self.layernorm(x)\n",
        "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
        "        return x_hat - bias\n",
        "\n",
        "\n",
        "class moving_avg(nn.Module):\n",
        "    \"\"\"\n",
        "    Moving average block to highlight the trend of time series\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super(moving_avg, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class series_decomp(nn.Module):\n",
        "    \"\"\"\n",
        "    Series decomposition block\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        super(series_decomp, self).__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder layer with the progressive decomposition architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
        "        self.decomp1 = series_decomp(moving_avg)\n",
        "        self.decomp2 = series_decomp(moving_avg)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "        x, _ = self.decomp1(x)\n",
        "        y = x\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        res, _ = self.decomp2(x + y)\n",
        "        return res, attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        attns = []\n",
        "        if self.conv_layers is not None:\n",
        "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                x = conv_layer(x)\n",
        "                attns.append(attn)\n",
        "            x, attn = self.attn_layers[-1](x)\n",
        "            attns.append(attn)\n",
        "        else:\n",
        "            for attn_layer in self.attn_layers:\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                attns.append(attn)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, attns"
      ],
      "metadata": {
        "id": "qpSP4bs9OPBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dataclasses"
      ],
      "metadata": {
        "id": "pePJTTvqO50n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclasses.dataclass\n",
        "class Config:\n",
        "    factor: int\n",
        "    dropout: float\n",
        "    output_attention: bool\n",
        "    n_heads: int\n",
        "    d_model: int\n",
        "    d_hid: int\n",
        "    kernel_size_mavg: int\n",
        "    e_layers: int\n",
        "    activation: str\n",
        "    d_window: int"
      ],
      "metadata": {
        "id": "PVqDSvKrPV4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config(\n",
        "    factor=1,\n",
        "    dropout=0.1,\n",
        "    output_attention=False,\n",
        "    n_heads=2,\n",
        "    d_model=6,\n",
        "    d_hid=128,\n",
        "    kernel_size_mavg=9,\n",
        "    e_layers=4,\n",
        "    activation='gelu',\n",
        "    d_window=30,\n",
        ")"
      ],
      "metadata": {
        "id": "BTN9W2N4QKOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(\n",
        "    [\n",
        "        EncoderLayer(\n",
        "            AutoCorrelationLayer(\n",
        "                    AutoCorrelation(False, config.factor,\n",
        "                                    attention_dropout=config.dropout,\n",
        "                                    output_attention=config.output_attention\n",
        "                                    ),\n",
        "                    config.d_model,\n",
        "                    config.n_heads),\n",
        "                config.d_model,\n",
        "                config.d_hid,\n",
        "                moving_avg=config.kernel_size_mavg,\n",
        "                dropout=config.dropout,\n",
        "                activation=config.activation\n",
        "            ) for l in range(config.e_layers)\n",
        "        ],\n",
        "        norm_layer=my_Layernorm(config.d_model)\n",
        "    ).to(device)"
      ],
      "metadata": {
        "id": "ZMKHTduaOves"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoCorrelationEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 config: Config,\n",
        "                 device: torch.device) -> None:\n",
        "      super().__init__()\n",
        "      self.d_model = config.d_model\n",
        "      self.d_window = config.d_window\n",
        "      self.device = device\n",
        "      self.encoder = Encoder(\n",
        "          [\n",
        "              EncoderLayer(\n",
        "              AutoCorrelationLayer(\n",
        "                  AutoCorrelation(False,\n",
        "                                  config.factor,\n",
        "                                  attention_dropout=config.dropout,\n",
        "                                  output_attention=config.output_attention\n",
        "                                  ),\n",
        "                  config.d_model,\n",
        "                  config.n_heads),\n",
        "              config.d_model,\n",
        "              config.d_hid,\n",
        "              moving_avg=config.kernel_size_mavg,\n",
        "              dropout=config.dropout,\n",
        "              activation=config.activation\n",
        "              ) for l in range(config.e_layers)\n",
        "          ],\n",
        "          norm_layer=my_Layernorm(config.d_model)\n",
        "          ).to(self.device)\n",
        "      self.mlp = nn.Linear(config.d_model * config.d_window, 1).to(self.device)\n",
        "\n",
        "      self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.mlp.bias.data.zero_()\n",
        "        self.mlp.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def make_mask(self, length):\n",
        "        nn.Transformer.generate_square_subsequent_mask(length).to(self.device)\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        mask = self.make_mask(length=x.shape[1])\n",
        "        outp = self.encoder(x, mask)[0]\n",
        "        outp = outp.view(-1, self.d_window * self.d_model)\n",
        "        outp = self.mlp(outp)\n",
        "        return outp.flatten()"
      ],
      "metadata": {
        "id": "PeGEM8hoS5OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "XETXsNO5OCel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 d_window: int,\n",
        "                 nhead: int,\n",
        "                 d_hid: int,\n",
        "                 nlayers: int,\n",
        "                 dropout: float = 0.1) -> None:\n",
        "      super().__init__()\n",
        "      encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
        "      self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
        "      self.d_input = d_model\n",
        "      self.mlp = nn.Linear(d_model, d_model)\n",
        "      self.linear = nn.Linear(d_window, d_model)\n",
        "      self.act = nn.ReLU()\n",
        "      self.final = nn.Linear(2 * d_model, 1)\n",
        "\n",
        "      self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        for layer in (self.mlp, self.linear, self.final):\n",
        "            layer.bias.data.zero_()\n",
        "            layer.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
        "        src_mask = src_mask or nn.Transformer.generate_square_subsequent_mask(\n",
        "            src.shape[1]\n",
        "            ).to(device)\n",
        "        linear_outp = self.act(self.linear(src[:, :, 0]))\n",
        "        attn_outp = self.transformer_encoder(src, src_mask)\n",
        "        mlp_outp = self.act(self.mlp(attn_outp)[:, -1])\n",
        "        features = torch.cat((mlp_outp, linear_outp), axis=1)\n",
        "        output = self.final(features)\n",
        "        return output"
      ],
      "metadata": {
        "id": "8j2srfWHe6Ti"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "02d0ZSrIVNE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(model: nn.Module, train_loader, epoch) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 100\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        x, y = batch\n",
        "        output = model(x).flatten()\n",
        "        targets = y[:, 0]\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if i % log_interval == 0 and i > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            cur_loss *= 10e6\n",
        "            print(f'epoch {epoch:3d} | {i:5d}/{len(train_loader):5d} batches | '\n",
        "                  f'lr {lr:2.5f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:0.4f} * 10^(-6)')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, test_loader) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(test_loader):\n",
        "            x, y = batch\n",
        "            output = model(x).flatten()\n",
        "            targets = y[:, 0]\n",
        "            total_loss += criterion(output, targets).item()\n",
        "    return total_loss / (len(test_loader))"
      ],
      "metadata": {
        "id": "qLWWo7u8pUYC"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(123456)\n",
        "\n",
        "model = SimpleTransformer(\n",
        "    d_model=train_dataset.shape[0],\n",
        "    d_window=30,\n",
        "    nhead=2,\n",
        "    d_hid=512,\n",
        "    nlayers=2\n",
        "    ).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.9)"
      ],
      "metadata": {
        "id": "AAYOyykG_qw5"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        train(model, train_loader, epoch)\n",
        "        val_loss = evaluate(model, test_loader)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {10e6 * val_loss:0.4f} * 10^(-6)')\n",
        "        print('-' * 89)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ],
      "metadata": {
        "id": "g3h5DIAmrESG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b8d34b-da0e-4e64-e8e3-512a88488e3d"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch   1 |   100/  542 batches | lr 0.00100 | ms/batch 24.42 | loss 146.7478 * 10^(-6)\n",
            "epoch   1 |   200/  542 batches | lr 0.00100 | ms/batch 22.61 | loss 152.0607 * 10^(-6)\n",
            "epoch   1 |   300/  542 batches | lr 0.00100 | ms/batch 26.62 | loss 151.5342 * 10^(-6)\n",
            "epoch   1 |   400/  542 batches | lr 0.00100 | ms/batch 23.49 | loss 174.3120 * 10^(-6)\n",
            "epoch   1 |   500/  542 batches | lr 0.00100 | ms/batch 21.79 | loss 92.2760 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 16.31s | valid loss 463.7904 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "epoch   2 |   100/  542 batches | lr 0.00090 | ms/batch 25.62 | loss 145.7522 * 10^(-6)\n",
            "epoch   2 |   200/  542 batches | lr 0.00090 | ms/batch 26.16 | loss 68.2979 * 10^(-6)\n",
            "epoch   2 |   300/  542 batches | lr 0.00090 | ms/batch 22.53 | loss 57.6073 * 10^(-6)\n",
            "epoch   2 |   400/  542 batches | lr 0.00090 | ms/batch 22.48 | loss 50.9961 * 10^(-6)\n",
            "epoch   2 |   500/  542 batches | lr 0.00090 | ms/batch 22.79 | loss 55.8543 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 16.80s | valid loss 343.5839 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "epoch   3 |   100/  542 batches | lr 0.00081 | ms/batch 25.49 | loss 82.9095 * 10^(-6)\n",
            "epoch   3 |   200/  542 batches | lr 0.00081 | ms/batch 23.03 | loss 48.2589 * 10^(-6)\n",
            "epoch   3 |   300/  542 batches | lr 0.00081 | ms/batch 22.83 | loss 91.9786 * 10^(-6)\n",
            "epoch   3 |   400/  542 batches | lr 0.00081 | ms/batch 22.10 | loss 88.4924 * 10^(-6)\n",
            "epoch   3 |   500/  542 batches | lr 0.00081 | ms/batch 25.31 | loss 42.8137 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 16.61s | valid loss 286.2063 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "epoch   4 |   100/  542 batches | lr 0.00073 | ms/batch 24.33 | loss 51.8795 * 10^(-6)\n",
            "epoch   4 |   200/  542 batches | lr 0.00073 | ms/batch 22.55 | loss 40.0153 * 10^(-6)\n",
            "epoch   4 |   300/  542 batches | lr 0.00073 | ms/batch 24.45 | loss 74.7172 * 10^(-6)\n",
            "epoch   4 |   400/  542 batches | lr 0.00073 | ms/batch 25.79 | loss 39.1124 * 10^(-6)\n",
            "epoch   4 |   500/  542 batches | lr 0.00073 | ms/batch 22.68 | loss 84.7105 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 16.31s | valid loss 261.9496 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "epoch   5 |   100/  542 batches | lr 0.00066 | ms/batch 24.49 | loss 77.4766 * 10^(-6)\n",
            "epoch   5 |   200/  542 batches | lr 0.00066 | ms/batch 28.10 | loss 29.9625 * 10^(-6)\n",
            "epoch   5 |   300/  542 batches | lr 0.00066 | ms/batch 22.76 | loss 45.1649 * 10^(-6)\n",
            "epoch   5 |   400/  542 batches | lr 0.00066 | ms/batch 23.18 | loss 63.3160 * 10^(-6)\n",
            "epoch   5 |   500/  542 batches | lr 0.00066 | ms/batch 25.25 | loss 59.4471 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 19.00s | valid loss 237.3355 * 10^(-6)\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets, predictions = [], []\n",
        "\n",
        "model.eval()\n",
        "for x, y in test_loader:\n",
        "    predictions += list(model(x).flatten().cpu().detach().numpy())\n",
        "    targets += list(y[:, 0].cpu().numpy())"
      ],
      "metadata": {
        "id": "DERDc85TszYH"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(targets, predictions)\n",
        "mape = mean_absolute_percentage_error(targets, predictions)\n",
        "r2 = r2_score(targets, predictions)\n",
        "\n",
        "print(f'MAPE = {mape:5.5f} | MSE = {mse * 1e6:.4f} * 10^(-6) | MSE improved: {mse < 0.00001518} | R^2 = {r2:5.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_i4VW5BxuXr",
        "outputId": "99575d53-b8ac-4fb2-b43d-e51ae337a301"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE = 0.10723 | MSE = 23.8087 * 10^(-6) | MSE improved: False | R^2 = 0.654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation"
      ],
      "metadata": {
        "id": "DDNypx5k7ePh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "Hs7L1O3W7dL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from captum.attr import (\n",
        "    GradientShap,\n",
        "    DeepLift,\n",
        "    DeepLiftShap,\n",
        "    IntegratedGradients,\n",
        "    LayerConductance,\n",
        "    NeuronConductance,\n",
        "    NoiseTunnel,\n",
        ")\n",
        "\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "wCFfSiez7cNj"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, _ = next(iter(test_loader))\n",
        "input = x\n",
        "baseline = torch.zeros_like(input)"
      ],
      "metadata": {
        "id": "BGEWlObl7ccU"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(torch.device('cpu'))\n",
        "input = input.to(torch.device('cpu'))\n",
        "baseline = baseline.to(torch.device('cpu'))"
      ],
      "metadata": {
        "id": "JTfKzkpiCt_U"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ig = IntegratedGradients(model)\n",
        "nt = NoiseTunnel(ig)\n",
        "attributions, delta = nt.attribute(input,\n",
        "                                   nt_type='smoothgrad',\n",
        "                                   stdevs=0.02,\n",
        "                                   nt_samples=4,\n",
        "                                   baselines=baseline,\n",
        "                                   target=0,\n",
        "                                   return_convergence_delta=True\n",
        "                                   )"
      ],
      "metadata": {
        "id": "V3YcB-UT7qL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Maximum convergence delta: {torch.max(torch.abs(delta))}')"
      ],
      "metadata": {
        "id": "5jCsWK4t90mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributions.mean(axis=0).T"
      ],
      "metadata": {
        "id": "3qqioqR692I3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}